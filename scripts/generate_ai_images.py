#!/usr/bin/env python3
"""
AI å›¾åƒç”Ÿæˆè„šæœ¬
æ”¯æŒå¤šç§å›¾åƒç”ŸæˆæœåŠ¡ï¼šOpenAI DALL-Eã€Google Imagen ç­‰
ä¸ºåˆ†é•œåœºæ™¯ç”Ÿæˆè®¾è®¡å‚è€ƒå›¾
"""

import os
import json
import base64
import requests
from pathlib import Path
from typing import Dict, List, Optional
import yaml
import time


class AIImageGenerator:
    """AI å›¾åƒç”Ÿæˆå™¨ - æ”¯æŒå¤šç§æœåŠ¡"""

    def __init__(self):
        """åˆå§‹åŒ–å›¾åƒç”Ÿæˆå™¨"""
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.google_api_key = os.getenv("GOOGLE_API_KEY")

        # æ£€æŸ¥å¯ç”¨çš„æœåŠ¡
        self.available_services = []
        if self.openai_api_key:
            self.available_services.append("openai")
        if self.google_api_key:
            self.available_services.append("google")

        if not self.available_services:
            print("âš ï¸  è­¦å‘Šï¼šæœªé…ç½®ä»»ä½•å›¾åƒç”ŸæˆæœåŠ¡çš„ API Key")
            print("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹ä¹‹ä¸€ï¼š")
            print("  - OPENAI_API_KEY (ç”¨äº DALL-E)")
            print("  - GOOGLE_API_KEY (ç”¨äº Imagen)")
            print("\nå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ç”Ÿæˆå ä½å›¾...")
            self.mock_mode = True
        else:
            self.mock_mode = False
            print(f"âœ… å¯ç”¨æœåŠ¡: {', '.join(self.available_services)}")

    def load_script(self, script_path: str) -> Dict:
        """åŠ è½½è„šæœ¬æ–‡ä»¶"""
        with open(script_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def extract_scenes(self, script_data: Dict) -> List[Dict]:
        """æå–åœºæ™¯ä¿¡æ¯"""
        scenes = []
        for scene in script_data.get('scenes', []):
            if 'image_generation_prompt' in scene:
                scenes.append({
                    'id': scene['id'],
                    'prompt': scene['image_generation_prompt'],
                    'narration': scene.get('narration', ''),
                    'duration': scene.get('duration', 0),
                    'storyboard': scene.get('storyboard', {})
                })
        return scenes

    def generate_with_openai_dalle(self, prompt: str, output_path: str) -> bool:
        """ä½¿ç”¨ OpenAI DALL-E ç”Ÿæˆå›¾åƒ

        Args:
            prompt: å›¾åƒæè¿°
            output_path: è¾“å‡ºè·¯å¾„

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # DALL-E 3 API
            url = "https://api.openai.com/v1/images/generations"
            headers = {
                "Authorization": f"Bearer {self.openai_api_key}",
                "Content-Type": "application/json"
            }

            # DALL-E 3 å‚æ•°
            data = {
                "model": "dall-e-3",
                "prompt": prompt[:4000],  # DALL-E 3 é™åˆ¶
                "n": 1,
                "size": "1792x1024",  # æ¥è¿‘ 16:9
                "quality": "hd",
                "style": "vivid"
            }

            print(f"      â³ è°ƒç”¨ DALL-E 3 ç”Ÿæˆå›¾åƒ...")
            response = requests.post(url, headers=headers, json=data, timeout=120)

            if response.status_code == 200:
                result = response.json()
                image_url = result['data'][0]['url']

                # ä¸‹è½½å›¾åƒ
                print(f"      â³ ä¸‹è½½å›¾åƒ...")
                img_response = requests.get(image_url, timeout=30)

                if img_response.status_code == 200:
                    with open(output_path, 'wb') as f:
                        f.write(img_response.content)
                    print(f"      âœ… å›¾åƒå·²ä¿å­˜")
                    return True
                else:
                    print(f"      âŒ ä¸‹è½½å¤±è´¥: {img_response.status_code}")
                    return False
            else:
                error_msg = response.json().get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                print(f"      âŒ ç”Ÿæˆå¤±è´¥: {error_msg}")
                return False

        except Exception as e:
            print(f"      âŒ å¼‚å¸¸: {str(e)}")
            return False

    def generate_with_stability(self, prompt: str, output_path: str) -> bool:
        """ä½¿ç”¨ Stability AI ç”Ÿæˆå›¾åƒï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰

        æ³¨æ„ï¼šéœ€è¦å•ç‹¬ç”³è¯· Stability AI API Key
        """
        stability_key = os.getenv("STABILITY_API_KEY")
        if not stability_key:
            return False

        # Stability AI å®ç°...
        return False

    def create_placeholder_image(self, scene: Dict, output_path: str):
        """åˆ›å»ºå ä½å›¾ï¼ˆå½“æ— æ³•ä½¿ç”¨AIç”Ÿæˆæ—¶ï¼‰"""
        from PIL import Image, ImageDraw, ImageFont

        # åˆ›å»º 16:9 å›¾åƒ
        width, height = 1920, 1080
        img = Image.new('RGB', (width, height), color='#2C2C2C')
        draw = ImageDraw.Draw(img)

        # å°è¯•åŠ è½½å­—ä½“
        try:
            font_large = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", 60)
            font_small = ImageFont.truetype("/System/Library/Fonts/PingFang.ttc", 30)
        except:
            font_large = ImageFont.load_default()
            font_small = ImageFont.load_default()

        # ç»˜åˆ¶åœºæ™¯ID
        scene_id = scene['id']
        draw.text((width//2, height//2 - 100), scene_id,
                 fill='white', font=font_large, anchor='mm')

        # ç»˜åˆ¶æç¤º
        draw.text((width//2, height//2 + 50),
                 "[ å ä½å›¾ - è¯·é…ç½® API Key ç”Ÿæˆå®é™…å›¾åƒ ]",
                 fill='#888888', font=font_small, anchor='mm')

        # ç»˜åˆ¶æ—ç™½ç‰‡æ®µ
        narration = scene.get('narration', '')[:50] + '...'
        draw.text((width//2, height//2 + 120),
                 narration,
                 fill='#666666', font=font_small, anchor='mm')

        img.save(output_path, quality=95)

    def generate_images(self, script_path: str, output_dir: str):
        """ä¸ºæ‰€æœ‰åœºæ™¯ç”Ÿæˆå›¾åƒ

        Args:
            script_path: è„šæœ¬æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
        """
        # åŠ è½½è„šæœ¬
        print(f"\nğŸ“– åŠ è½½è„šæœ¬: {script_path}")
        script_data = self.load_script(script_path)

        # æå–åœºæ™¯
        scenes = self.extract_scenes(script_data)
        print(f"âœ… æ‰¾åˆ° {len(scenes)} ä¸ªåœºæ™¯\n")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆå›¾åƒ
        success_count = 0
        failed_scenes = []

        for i, scene in enumerate(scenes, 1):
            scene_id = scene['id']
            print(f"ğŸ¨ [{i}/{len(scenes)}] {scene_id}")
            print(f"   æ—¶é•¿: {scene['duration']}ç§’")
            print(f"   æ—ç™½: {scene['narration'][:50]}...")

            # è¾“å‡ºè·¯å¾„
            img_path = output_path / f"{scene_id}_ai_generated.png"

            # å¦‚æœå·²å­˜åœ¨ï¼Œè·³è¿‡
            if img_path.exists():
                print(f"   â­ï¸  å·²å­˜åœ¨ï¼Œè·³è¿‡")
                success_count += 1
                continue

            # å°è¯•ç”Ÿæˆ
            success = False

            if not self.mock_mode:
                # ä½¿ç”¨çœŸå® AI æœåŠ¡
                if "openai" in self.available_services:
                    success = self.generate_with_openai_dalle(
                        scene['prompt'],
                        str(img_path)
                    )

                    # DALL-E API æœ‰é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…ä¸€ä¸‹
                    if success and i < len(scenes):
                        print(f"      â³ ç­‰å¾… 3 ç§’ï¼ˆé¿å…é€Ÿç‡é™åˆ¶ï¼‰...")
                        time.sleep(3)

            # å¦‚æœå¤±è´¥æˆ–æ¨¡æ‹Ÿæ¨¡å¼ï¼Œåˆ›å»ºå ä½å›¾
            if not success:
                if self.mock_mode:
                    print(f"   ğŸ“ åˆ›å»ºå ä½å›¾...")
                else:
                    print(f"   ğŸ“ ç”Ÿæˆå¤±è´¥ï¼Œåˆ›å»ºå ä½å›¾...")

                self.create_placeholder_image(scene, str(img_path))

            success_count += 1
            print()

        # æ€»ç»“
        print("=" * 60)
        print(f"âœ… å®Œæˆï¼æˆåŠŸç”Ÿæˆ {success_count}/{len(scenes)} å¼ å›¾åƒ")

        if failed_scenes:
            print(f"\nâš ï¸  ä»¥ä¸‹åœºæ™¯ç”Ÿæˆå¤±è´¥ï¼š")
            for scene_id in failed_scenes:
                print(f"   - {scene_id}")

        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="ä¸ºåˆ†é•œåœºæ™¯ç”Ÿæˆ AI å›¾åƒ")
    parser.add_argument(
        "--script",
        default="./æ–‡è„‰è–ªä¼ _ç»†åŒ–è„šæœ¬.yaml",
        help="è„šæœ¬æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--output",
        default="./storyboards/æ–‡è„‰è–ªä¼ /ai_generated_images",
        help="è¾“å‡ºç›®å½•"
    )

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ¨ AI å›¾åƒç”Ÿæˆå™¨")
    print("=" * 60)

    # åˆ›å»ºç”Ÿæˆå™¨
    generator = AIImageGenerator()

    # ç”Ÿæˆå›¾åƒ
    generator.generate_images(args.script, args.output)

    print("\nğŸ’¡ æç¤ºï¼š")
    if generator.mock_mode:
        print("  1. å½“å‰ä¸ºæ¨¡æ‹Ÿæ¨¡å¼ï¼ˆç”Ÿæˆå ä½å›¾ï¼‰")
        print("  2. è¦ç”ŸæˆçœŸå®å›¾åƒï¼Œè¯·é…ç½® API Keyï¼š")
        print("     - OPENAI_API_KEY (DALL-E)")
        print("     - GOOGLE_API_KEY (Imagen)")
    else:
        print("  1. å›¾åƒå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹è¾“å‡ºç›®å½•")
        print("  2. å¯ä»¥å°†è¿™äº›å›¾åƒç”¨ä½œè§†é¢‘åˆ¶ä½œçš„å‚è€ƒ")
    print("  3. ä¹Ÿå¯ä»¥ä½¿ç”¨æç¤ºè¯åœ¨ Midjourney ä¸­ç”Ÿæˆæ›´ç²¾ç¾çš„å›¾åƒ")


if __name__ == "__main__":
    main()
