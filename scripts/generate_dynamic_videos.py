#!/usr/bin/env python3
"""
æ··åˆæ–¹æ¡ˆåŠ¨æ€è§†é¢‘ç”Ÿæˆå™¨
- å…³é”®åˆ†é•œï¼šä½¿ç”¨ VEO3 AI ç”ŸæˆçœŸå®åŠ¨æ€è§†é¢‘
- æ™®é€šåˆ†é•œï¼šä½¿ç”¨å¢å¼ºç‰ˆ Ken Burns æ•ˆæœï¼ˆç¼©æ”¾ã€å¹³ç§»ã€åŠ¨æ€æ¨¡ç³Šï¼‰
"""

import os
import yaml
import subprocess
import asyncio
import time
from pathlib import Path
from typing import List, Dict, Optional
from google import genai
from google.genai.types import GenerateVideosConfig, Image
import edge_tts
from gcs_utils import GCSHelper


class DynamicVideoGenerator:
    """æ··åˆæ–¹æ¡ˆåŠ¨æ€è§†é¢‘ç”Ÿæˆå™¨"""

    def __init__(
        self,
        script_path: str,
        image_dir: str,
        keyframe_dir: str,
        output_dir: str,
        gcs_bucket: str = None,
        use_veo: bool = True
    ):
        """åˆå§‹åŒ–

        Args:
            script_path: è„šæœ¬æ–‡ä»¶è·¯å¾„
            image_dir: èµ·å§‹å¸§å›¾ç‰‡ç›®å½•
            keyframe_dir: å…³é”®å¸§å›¾ç‰‡ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            gcs_bucket: Google Cloud Storage bucket (ç”¨äºVEO3, æ ¼å¼: gs://bucket-name/prefix)
            use_veo: æ˜¯å¦å¯ç”¨VEO3 (é»˜è®¤Trueï¼Œå…³é”®åˆ†é•œä½¿ç”¨AI)
        """
        self.script_path = script_path
        self.image_dir = Path(image_dir)
        self.keyframe_dir = Path(keyframe_dir)
        self.output_dir = Path(output_dir)
        self.gcs_bucket = gcs_bucket
        self.use_veo = use_veo and gcs_bucket is not None

        # åˆ›å»ºå­ç›®å½•
        self.video_dir = self.output_dir / "videos"
        self.audio_dir = self.output_dir / "audio"
        self.temp_dir = self.output_dir / "temp"
        self.veo_cache_dir = self.output_dir / "veo_cache"

        for d in [self.video_dir, self.audio_dir, self.temp_dir, self.veo_cache_dir]:
            d.mkdir(parents=True, exist_ok=True)

        # åŠ è½½è„šæœ¬
        with open(script_path, 'r', encoding='utf-8') as f:
            self.script_data = yaml.safe_load(f)

        self.scenes = self.script_data.get('scenes', [])
        self.voice = self.script_data.get('project', {}).get('voice', 'zh-CN-YunxiNeural')

        # åˆå§‹åŒ–VEOå®¢æˆ·ç«¯å’ŒGCS helper
        if self.use_veo:
            try:
                self.veo_client = genai.Client()

                # è§£æbucketåç§°
                bucket_name = gcs_bucket.replace('gs://', '').split('/')[0]
                self.gcs_prefix = '/'.join(gcs_bucket.replace('gs://', '').split('/')[1:])
                self.gcs_helper = GCSHelper(bucket_name)

                print(f"âœ… VEO3 å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
                print(f"   GCS Bucket: {bucket_name}")
                print(f"   GCS Prefix: {self.gcs_prefix}")
            except Exception as e:
                print(f"âš ï¸  VEO3 åˆå§‹åŒ–å¤±è´¥: {e}")
                print(f"   å°†å›é€€åˆ°çº¯æœ¬åœ°å¤„ç†")
                self.use_veo = False

        print(f"âœ… åŠ è½½äº† {len(self.scenes)} ä¸ªåœºæ™¯")
        print(f"ğŸ™ï¸  ä½¿ç”¨è¯­éŸ³: {self.voice}")
        print(f"ğŸ¬ VEO3 çŠ¶æ€: {'å¯ç”¨' if self.use_veo else 'ç¦ç”¨'}")

    def is_key_scene(self, scene: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå…³é”®åˆ†é•œï¼ˆéœ€è¦ä½¿ç”¨AIç”Ÿæˆï¼‰

        åˆ¤æ–­æ ‡å‡†ï¼š
        1. åœºæ™¯æ ‡è®°ä¸º 'key': true
        2. æ—¶é•¿ >= 4ç§’
        3. åœºæ™¯æè¿°åŒ…å«åŠ¨ä½œè¯æ±‡
        """
        # æ˜¾å¼æ ‡è®°
        if scene.get('key', False):
            return True

        # æ—¶é•¿åˆ¤æ–­
        if scene.get('duration', 0) >= 4:
            return True

        # åŠ¨ä½œè¯æ±‡åˆ¤æ–­
        action_keywords = ['é£è¡Œ', 'ç§»åŠ¨', 'å¥”è·‘', 'è·³è·ƒ', 'æ—‹è½¬', 'é£˜åŠ¨', 'æµåŠ¨', 'ç”Ÿé•¿']
        description = scene.get('description', '') + scene.get('narration', '')

        for keyword in action_keywords:
            if keyword in description:
                return True

        return False

    async def generate_narration_audio(self, scene_id: str, narration: str) -> Path:
        """ç”Ÿæˆç”»å¤–éŸ³éŸ³é¢‘"""
        audio_path = self.audio_dir / f"{scene_id}.mp3"

        if audio_path.exists():
            return audio_path

        communicate = edge_tts.Communicate(narration, self.voice)
        await communicate.save(str(audio_path))

        return audio_path

    def get_audio_duration(self, audio_path: Path) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        cmd = [
            'ffprobe', '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        return float(result.stdout.strip())

    async def generate_veo_video(
        self,
        image_path: Path,
        prompt: str,
        duration: float,
        scene_id: str
    ) -> Optional[Path]:
        """ä½¿ç”¨VEO3ç”ŸæˆåŠ¨æ€è§†é¢‘

        Args:
            image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
            prompt: è§†é¢‘ç”Ÿæˆæç¤ºè¯
            duration: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
            scene_id: åœºæ™¯ID

        Returns:
            ç”Ÿæˆçš„è§†é¢‘è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.use_veo:
            return None

        output_video = self.veo_cache_dir / f"{scene_id}_veo.mp4"

        # æ£€æŸ¥ç¼“å­˜
        if output_video.exists():
            print(f"   â­ï¸  VEOè§†é¢‘å·²å­˜åœ¨ï¼Œä½¿ç”¨ç¼“å­˜")
            return output_video

        try:
            print(f"   ğŸ¤– è°ƒç”¨VEO3ç”Ÿæˆè§†é¢‘...")
            print(f"      æç¤ºè¯: {prompt[:60]}...")

            # ä¸Šä¼ å›¾ç‰‡åˆ°GCS
            gcs_image_path = f"{self.gcs_prefix}/images/{scene_id}.png"
            print(f"   ğŸ“¤ ä¸Šä¼ å›¾ç‰‡åˆ°GCS...")
            gcs_image_uri = self.gcs_helper.upload_image(image_path, gcs_image_path)

            # è°ƒç”¨VEO3 API
            operation = self.veo_client.models.generate_videos(
                model="veo-3.1-generate-001",
                prompt=prompt,
                image=Image(
                    gcs_uri=gcs_image_uri,
                    mime_type="image/png",
                ),
                config=GenerateVideosConfig(
                    aspect_ratio="16:9",
                    output_gcs_uri=f"gs://{self.gcs_helper.bucket_name}/{self.gcs_prefix}/videos/",
                ),
            )

            # ç­‰å¾…ç”Ÿæˆå®Œæˆ
            print(f"   â³ ç­‰å¾…VEO3ç”Ÿæˆï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
            retry_count = 0
            max_retries = 120  # æœ€å¤šç­‰å¾…30åˆ†é’Ÿ

            while not operation.done and retry_count < max_retries:
                time.sleep(15)
                operation = self.veo_client.operations.get(operation)
                retry_count += 1

                if retry_count % 4 == 0:  # æ¯åˆ†é’Ÿæ‰“å°ä¸€æ¬¡
                    print(f"      ç­‰å¾…ä¸­... ({retry_count * 15}ç§’)")

            if operation.response:
                video_gcs_uri = operation.result.generated_videos[0].video.uri
                print(f"   âœ… VEO3ç”Ÿæˆå®Œæˆ: {video_gcs_uri}")

                # ä¸‹è½½è§†é¢‘
                print(f"   ğŸ“¥ ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°...")
                self.gcs_helper.download_video(video_gcs_uri, output_video)

                return output_video
            else:
                print(f"   âŒ VEO3ç”Ÿæˆè¶…æ—¶")
                return None

        except Exception as e:
            print(f"   âš ï¸  VEO3ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def create_ken_burns_video(
        self,
        image_path: Path,
        duration: float,
        output_path: Path,
        effect: str = "zoom_in"
    ):
        """åˆ›å»ºKen Burnsæ•ˆæœè§†é¢‘ï¼ˆç¼©æ”¾+å¹³ç§»ï¼‰

        Args:
            image_path: è¾“å…¥å›¾ç‰‡
            duration: è§†é¢‘æ—¶é•¿
            output_path: è¾“å‡ºè·¯å¾„
            effect: æ•ˆæœç±»å‹ (zoom_in, zoom_out, pan_left, pan_right, diagonal)
        """

        # å®šä¹‰ä¸åŒçš„Ken Burnsæ•ˆæœ
        effects = {
            "zoom_in": {
                "scale": "scale='if(eq(iw/ih,16/9),iw,ih*16/9)':'if(eq(iw/ih,16/9),ih,iw*9/16)',zoompan=z='min(zoom+0.001,1.3)':d={frames}:s=2048x1152:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'",
                "description": "ç¼“æ…¢æ”¾å¤§"
            },
            "zoom_out": {
                "scale": "scale='if(eq(iw/ih,16/9),iw,ih*16/9)':'if(eq(iw/ih,16/9),ih,iw*9/16)',zoompan=z='if(lte(zoom,1.0),1.3,max(1.0,zoom-0.001))':d={frames}:s=2048x1152:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'",
                "description": "ç¼“æ…¢ç¼©å°"
            },
            "pan_right": {
                "scale": "scale='if(eq(iw/ih,16/9),iw,ih*16/9)':'if(eq(iw/ih,16/9),ih,iw*9/16)',zoompan=z='1.2':d={frames}:s=2048x1152:x='min(iw/zoom/2,iw-iw/zoom-iw/zoom*t/{duration})':y='ih/2-(ih/zoom/2)'",
                "description": "å‘å³å¹³ç§»"
            },
            "pan_left": {
                "scale": "scale='if(eq(iw/ih,16/9),iw,ih*16/9)':'if(eq(iw/ih,16/9),ih,iw*9/16)',zoompan=z='1.2':d={frames}:s=2048x1152:x='iw-iw/zoom-min(iw/zoom/2,iw-iw/zoom-iw/zoom*t/{duration})':y='ih/2-(ih/zoom/2)'",
                "description": "å‘å·¦å¹³ç§»"
            },
            "diagonal": {
                "scale": "scale='if(eq(iw/ih,16/9),iw,ih*16/9)':'if(eq(iw/ih,16/9),ih,iw*9/16)',zoompan=z='min(zoom+0.0008,1.2)':d={frames}:s=2048x1152:x='iw/2-(iw/zoom/2)-iw/zoom*0.3*t/{duration}':y='ih/2-(ih/zoom/2)-ih/zoom*0.2*t/{duration}'",
                "description": "å¯¹è§’çº¿ç§»åŠ¨"
            }
        }

        frames = int(duration * 30)
        effect_config = effects.get(effect, effects["zoom_in"])
        filter_str = effect_config["scale"].format(frames=frames, duration=duration)

        cmd = [
            'ffmpeg', '-y',
            '-loop', '1',
            '-i', str(image_path),
            '-vf', filter_str,
            '-t', str(duration),
            '-c:v', 'libx264',
            '-pix_fmt', 'yuv420p',
            '-r', '30',
            str(output_path)
        ]

        subprocess.run(cmd, check=True, capture_output=True)

    def add_subtitle_to_video(
        self,
        video_path: Path,
        subtitle_text: str,
        output_path: Path
    ):
        """ä¸ºè§†é¢‘æ·»åŠ å­—å¹•"""

        fontfile = '/System/Library/Fonts/PingFang.ttc'
        fontsize = 32
        fontcolor = 'white'
        box = 1
        boxcolor = 'black@0.5'

        subtitle_escaped = subtitle_text.replace("'", "'\\''").replace(":", "\\:")

        filter_str = (
            f"drawtext=text='{subtitle_escaped}':"
            f"fontfile='{fontfile}':"
            f"fontsize={fontsize}:"
            f"fontcolor={fontcolor}:"
            f"box={box}:"
            f"boxcolor={boxcolor}:"
            f"x=(w-text_w)/2:"
            f"y=h-100"
        )

        cmd = [
            'ffmpeg', '-y',
            '-i', str(video_path),
            '-vf', filter_str,
            '-c:v', 'libx264',
            '-pix_fmt', 'yuv420p',
            '-c:a', 'copy',
            str(output_path)
        ]

        subprocess.run(cmd, check=True, capture_output=True)

    def merge_video_audio(
        self,
        video_path: Path,
        audio_path: Path,
        output_path: Path
    ):
        """åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘"""
        cmd = [
            'ffmpeg', '-y',
            '-i', str(video_path),
            '-i', str(audio_path),
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-shortest',
            str(output_path)
        ]
        subprocess.run(cmd, check=True, capture_output=True)

    async def create_scene_video(self, scene_index: int):
        """ä¸ºå•ä¸ªåœºæ™¯åˆ›å»ºåŠ¨æ€è§†é¢‘"""
        scene = self.scenes[scene_index]
        scene_id = scene['id']
        duration = scene['duration']
        narration = scene.get('narration', '')
        description = scene.get('description', '')

        print(f"\nğŸ¬ åœºæ™¯ {scene_index + 1}/{len(self.scenes)}: {scene_id}")
        print(f"   â±ï¸  æ—¶é•¿: {duration}ç§’")
        print(f"   ğŸ“ æè¿°: {description[:50]}...")

        # åˆ¤æ–­æ˜¯å¦ä¸ºå…³é”®åˆ†é•œ
        is_key = self.is_key_scene(scene)
        print(f"   {'ğŸ”‘ å…³é”®åˆ†é•œ (ä½¿ç”¨VEO3)' if is_key else 'ğŸ“¹ æ™®é€šåˆ†é•œ (ä½¿ç”¨Ken Burns)'}")

        # 1. ç”Ÿæˆç”»å¤–éŸ³
        audio_path = await self.generate_narration_audio(scene_id, narration)
        audio_duration = self.get_audio_duration(audio_path)
        actual_duration = max(duration, audio_duration + 0.5)

        # è·å–å›¾ç‰‡
        keyframe = self.keyframe_dir / f"{scene_id}_keyframe.png"
        if not keyframe.exists():
            raise FileNotFoundError(f"å…³é”®å¸§ä¸å­˜åœ¨: {keyframe}")

        # 2. ç”Ÿæˆè§†é¢‘ï¼ˆVEO3 æˆ– Ken Burnsï¼‰
        video_no_subtitle = self.temp_dir / f"{scene_id}_no_subtitle.mp4"

        if is_key and self.use_veo:
            # ä½¿ç”¨VEO3ç”Ÿæˆ
            veo_prompt = f"{description}ã€‚ç”»é¢éœ€è¦æœ‰è‡ªç„¶çš„åŠ¨æ€æ•ˆæœã€‚"
            veo_video = await self.generate_veo_video(
                keyframe,
                veo_prompt,
                actual_duration,
                scene_id
            )

            if veo_video and veo_video.exists():
                # æˆåŠŸä½¿ç”¨VEO
                video_no_subtitle = veo_video
            else:
                # VEOå¤±è´¥ï¼Œå›é€€åˆ°Ken Burns
                print(f"   âš ï¸  å›é€€åˆ°Ken Burnsæ•ˆæœ")
                self.create_ken_burns_video(
                    keyframe,
                    actual_duration,
                    video_no_subtitle,
                    effect="zoom_in"
                )
        else:
            # ä½¿ç”¨Ken Burnsæ•ˆæœ
            # æ ¹æ®åœºæ™¯é€‰æ‹©ä¸åŒæ•ˆæœ
            effects = ["zoom_in", "zoom_out", "pan_right", "pan_left", "diagonal"]
            effect = effects[scene_index % len(effects)]

            print(f"   ğŸ¨ åº”ç”¨Ken Burnsæ•ˆæœ: {effect}")
            self.create_ken_burns_video(
                keyframe,
                actual_duration,
                video_no_subtitle,
                effect=effect
            )

        # 3. æ·»åŠ å­—å¹•
        video_with_subtitle = self.temp_dir / f"{scene_id}_subtitle.mp4"

        print(f"   ğŸ“ æ·»åŠ å­—å¹•...")
        self.add_subtitle_to_video(
            video_no_subtitle,
            narration,
            video_with_subtitle
        )

        # 4. åˆå¹¶éŸ³é¢‘
        output_video = self.video_dir / f"{scene_id}.mp4"

        print(f"   ğŸµ åˆå¹¶éŸ³é¢‘...")
        self.merge_video_audio(
            video_with_subtitle,
            audio_path,
            output_video
        )

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if video_no_subtitle != output_video:
            video_no_subtitle.unlink(missing_ok=True)
        video_with_subtitle.unlink(missing_ok=True)

        print(f"   âœ… å®Œæˆ: {output_video.name}")
        return output_video

    async def generate_all_videos(self):
        """ç”Ÿæˆæ‰€æœ‰åœºæ™¯è§†é¢‘"""
        print("=" * 70)
        print("ğŸ¬ æ··åˆæ–¹æ¡ˆåŠ¨æ€è§†é¢‘ç”Ÿæˆ")
        print("=" * 70)

        success_count = 0
        failed_scenes = []
        key_scenes_count = sum(1 for s in self.scenes if self.is_key_scene(s))

        print(f"\nğŸ“Š ç»Ÿè®¡:")
        print(f"   æ€»åœºæ™¯æ•°: {len(self.scenes)}")
        print(f"   å…³é”®åˆ†é•œ: {key_scenes_count} (ä½¿ç”¨VEO3)")
        print(f"   æ™®é€šåˆ†é•œ: {len(self.scenes) - key_scenes_count} (ä½¿ç”¨Ken Burns)")
        print()

        for i in range(len(self.scenes)):
            try:
                await self.create_scene_video(i)
                success_count += 1
            except Exception as e:
                scene_id = self.scenes[i]['id']
                print(f"   âŒ å¤±è´¥: {str(e)}")
                failed_scenes.append((scene_id, str(e)))

        print("\n" + "=" * 70)
        print(f"âœ… å®Œæˆï¼æˆåŠŸç”Ÿæˆ {success_count}/{len(self.scenes)} ä¸ªè§†é¢‘")

        if failed_scenes:
            print(f"\nâš ï¸  å¤±è´¥åœºæ™¯ï¼š")
            for sid, error in failed_scenes:
                print(f"   - {sid}: {error[:60]}")

        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {self.video_dir}")
        print("=" * 70)


async def main():
    """ä¸»å‡½æ•°"""

    # é…ç½®
    GCS_BUCKET = os.getenv('GCS_BUCKET')  # ä»ç¯å¢ƒå˜é‡è¯»å–
    USE_VEO = os.getenv('USE_VEO', 'true').lower() == 'true'

    if not GCS_BUCKET:
        print("âš ï¸  æœªè®¾ç½® GCS_BUCKET ç¯å¢ƒå˜é‡")
        print("   å°†ç¦ç”¨VEO3åŠŸèƒ½ï¼Œä»…ä½¿ç”¨Ken Burnsæ•ˆæœ")
        print("   å¦‚éœ€å¯ç”¨VEO3ï¼Œè¯·è®¾ç½®:")
        print("   export GCS_BUCKET='gs://your-bucket/prefix'")
        print()

    generator = DynamicVideoGenerator(
        script_path='./æ–‡è„‰è–ªä¼ _ç»†åŒ–è„šæœ¬.yaml',
        image_dir='./storyboards/æ–‡è„‰è–ªä¼ /doubao_images',
        keyframe_dir='./storyboards/æ–‡è„‰è–ªä¼ /keyframes',
        output_dir='./storyboards/æ–‡è„‰è–ªä¼ /dynamic_videos',
        gcs_bucket=GCS_BUCKET,
        use_veo=USE_VEO
    )

    await generator.generate_all_videos()


if __name__ == "__main__":
    asyncio.run(main())
