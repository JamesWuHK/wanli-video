#!/usr/bin/env python3
"""
ä¸ºæ¯ä¸ªåˆ†é•œç”Ÿæˆå®Œæ•´è§†é¢‘
åŒ…å«ï¼šè¿‡æ¸¡åŠ¨ç”» + å­—å¹• + ç”»å¤–éŸ³è§£è¯´
"""

import os
import yaml
import subprocess
import asyncio
from pathlib import Path
from typing import List, Dict
import edge_tts


class SceneVideoGenerator:
    """å®Œæ•´åˆ†é•œè§†é¢‘ç”Ÿæˆå™¨"""

    def __init__(self, script_path: str, image_dir: str, keyframe_dir: str, output_dir: str):
        """åˆå§‹åŒ–"""
        self.script_path = script_path
        self.image_dir = Path(image_dir)
        self.keyframe_dir = Path(keyframe_dir)
        self.output_dir = Path(output_dir)
        self.audio_dir = self.output_dir / "audio"
        self.temp_dir = self.output_dir / "temp"

        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.audio_dir.mkdir(parents=True, exist_ok=True)
        self.temp_dir.mkdir(parents=True, exist_ok=True)

        # åŠ è½½è„šæœ¬
        with open(script_path, 'r', encoding='utf-8') as f:
            self.script_data = yaml.safe_load(f)

        self.scenes = self.script_data.get('scenes', [])
        self.voice = self.script_data.get('project', {}).get('voice', 'zh-CN-YunxiNeural')

        print(f"âœ… åŠ è½½äº† {len(self.scenes)} ä¸ªåœºæ™¯")
        print(f"ğŸ™ï¸  ä½¿ç”¨è¯­éŸ³: {self.voice}")

    async def generate_narration_audio(self, scene_id: str, narration: str) -> Path:
        """ç”Ÿæˆç”»å¤–éŸ³éŸ³é¢‘"""
        audio_path = self.audio_dir / f"{scene_id}.mp3"

        if audio_path.exists():
            print(f"   â­ï¸  éŸ³é¢‘å·²å­˜åœ¨ï¼Œè·³è¿‡")
            return audio_path

        print(f"   ğŸ™ï¸  ç”Ÿæˆç”»å¤–éŸ³...")

        communicate = edge_tts.Communicate(narration, self.voice)
        await communicate.save(str(audio_path))

        return audio_path

    def get_audio_duration(self, audio_path: Path) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        cmd = [
            'ffprobe', '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        return float(result.stdout.strip())

    def create_image_video_with_subtitle(
        self,
        image_path: Path,
        duration: float,
        subtitle_text: str,
        output_path: Path
    ):
        """ä»å›¾ç‰‡åˆ›å»ºå¸¦å­—å¹•çš„è§†é¢‘ç‰‡æ®µ"""

        # å­—å¹•æ ·å¼è®¾ç½®
        fontfile = '/System/Library/Fonts/PingFang.ttc'  # macOSä¸­æ–‡å­—ä½“
        fontsize = 32
        fontcolor = 'white'
        box = 1
        boxcolor = 'black@0.5'

        # è½¬ä¹‰å­—å¹•æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦
        subtitle_escaped = subtitle_text.replace("'", "'\\''").replace(":", "\\:")

        filter_complex = (
            f"[0:v]scale=2048:1152,fps=30,"
            f"drawtext=text='{subtitle_escaped}':"
            f"fontfile='{fontfile}':"
            f"fontsize={fontsize}:"
            f"fontcolor={fontcolor}:"
            f"box={box}:"
            f"boxcolor={boxcolor}:"
            f"x=(w-text_w)/2:"
            f"y=h-100"
        )

        cmd = [
            'ffmpeg', '-y',
            '-loop', '1',
            '-i', str(image_path),
            '-filter_complex', filter_complex,
            '-t', str(duration),
            '-c:v', 'libx264',
            '-pix_fmt', 'yuv420p',
            '-r', '30',
            str(output_path)
        ]

        subprocess.run(cmd, check=True, capture_output=True)

    def create_transition_video(
        self,
        img1_path: Path,
        img2_path: Path,
        duration: float,
        output_path: Path,
        transition_type: str = "fade"
    ):
        """åˆ›å»ºè¿‡æ¸¡è§†é¢‘"""

        cmd = [
            'ffmpeg', '-y',
            '-loop', '1', '-t', str(duration), '-i', str(img1_path),
            '-loop', '1', '-t', str(duration), '-i', str(img2_path),
            '-filter_complex',
            f"[0:v][1:v]xfade=transition={transition_type}:duration=0.5:offset={duration-0.5}",
            '-t', str(duration * 2 - 0.5),
            '-c:v', 'libx264',
            '-pix_fmt', 'yuv420p',
            '-r', '30',
            str(output_path)
        ]

        subprocess.run(cmd, check=True, capture_output=True)

    def merge_video_audio(self, video_path: Path, audio_path: Path, output_path: Path):
        """åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘"""
        cmd = [
            'ffmpeg', '-y',
            '-i', str(video_path),
            '-i', str(audio_path),
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-shortest',
            str(output_path)
        ]
        subprocess.run(cmd, check=True, capture_output=True)

    async def create_scene_video(self, scene_index: int):
        """ä¸ºå•ä¸ªåœºæ™¯åˆ›å»ºå®Œæ•´è§†é¢‘"""
        scene = self.scenes[scene_index]
        scene_id = scene['id']
        duration = scene['duration']
        narration = scene['narration']

        print(f"\nğŸ¬ åœºæ™¯ {scene_index + 1}/{len(self.scenes)}: {scene_id}")
        print(f"   â±ï¸  æ—¶é•¿: {duration}ç§’")
        print(f"   ğŸ“ æ—ç™½: {narration[:50]}...")

        # 1. ç”Ÿæˆç”»å¤–éŸ³
        audio_path = await self.generate_narration_audio(scene_id, narration)
        audio_duration = self.get_audio_duration(audio_path)

        # ä½¿ç”¨éŸ³é¢‘æ—¶é•¿ä½œä¸ºå®é™…è§†é¢‘æ—¶é•¿ï¼ˆç¡®ä¿æ—¶é—´è½´åŒ¹é…ï¼‰
        actual_duration = max(duration, audio_duration + 0.5)

        print(f"   ğŸ™ï¸  éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}ç§’")
        print(f"   ğŸ“¹ å®é™…è§†é¢‘æ—¶é•¿: {actual_duration:.2f}ç§’")

        # å›¾ç‰‡è·¯å¾„
        start_frame = self.image_dir / f"{scene_id}.png"
        keyframe = self.keyframe_dir / f"{scene_id}_keyframe.png"

        if not start_frame.exists() or not keyframe.exists():
            raise FileNotFoundError(f"å›¾ç‰‡ä¸å­˜åœ¨: {scene_id}")

        # 2. åˆ›å»ºå¸¦å­—å¹•çš„è§†é¢‘ç‰‡æ®µ
        segment_duration = actual_duration / 2  # å‡åˆ†ä¸ºå¼€å§‹å¸§å’Œå…³é”®å¸§ä¸¤éƒ¨åˆ†

        seg1_path = self.temp_dir / f"{scene_id}_seg1_subtitle.mp4"
        seg2_path = self.temp_dir / f"{scene_id}_seg2_subtitle.mp4"

        print(f"   ğŸ¨ åˆ›å»ºå¼€å§‹å¸§è§†é¢‘ï¼ˆå¸¦å­—å¹•ï¼‰...")
        self.create_image_video_with_subtitle(
            start_frame,
            segment_duration,
            narration,
            seg1_path
        )

        print(f"   ğŸ¨ åˆ›å»ºå…³é”®å¸§è§†é¢‘ï¼ˆå¸¦å­—å¹•ï¼‰...")
        self.create_image_video_with_subtitle(
            keyframe,
            segment_duration,
            narration,
            seg2_path
        )

        # 3. åˆ›å»ºè¿‡æ¸¡æ•ˆæœï¼ˆå¼€å§‹å¸§åˆ°å…³é”®å¸§ï¼‰
        print(f"   ğŸ”€ æ·»åŠ è¿‡æ¸¡æ•ˆæœ...")
        transition_path = self.temp_dir / f"{scene_id}_transition.mp4"

        cmd = [
            'ffmpeg', '-y',
            '-i', str(seg1_path),
            '-i', str(seg2_path),
            '-filter_complex',
            '[0:v][1:v]xfade=transition=fade:duration=1:offset=' + str(segment_duration - 1),
            '-c:v', 'libx264',
            '-pix_fmt', 'yuv420p',
            '-r', '30',
            str(transition_path)
        ]
        subprocess.run(cmd, check=True, capture_output=True)

        # 4. åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
        output_video = self.output_dir / f"{scene_id}.mp4"

        print(f"   ğŸµ åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘...")
        self.merge_video_audio(transition_path, audio_path, output_video)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        seg1_path.unlink(missing_ok=True)
        seg2_path.unlink(missing_ok=True)
        transition_path.unlink(missing_ok=True)

        print(f"   âœ… å®Œæˆ: {output_video.name}")
        return output_video

    async def generate_all_videos(self):
        """ç”Ÿæˆæ‰€æœ‰åœºæ™¯è§†é¢‘"""
        print("=" * 60)
        print("ğŸ¬ å¼€å§‹ç”Ÿæˆæ‰€æœ‰åˆ†é•œè§†é¢‘ï¼ˆå¸¦ç”»å¤–éŸ³å’Œå­—å¹•ï¼‰")
        print("=" * 60)

        success_count = 0
        failed_scenes = []

        for i in range(len(self.scenes)):
            try:
                await self.create_scene_video(i)
                success_count += 1
            except Exception as e:
                scene_id = self.scenes[i]['id']
                print(f"   âŒ å¤±è´¥: {str(e)}")
                failed_scenes.append((scene_id, str(e)))

        print("\n" + "=" * 60)
        print(f"âœ… å®Œæˆï¼æˆåŠŸç”Ÿæˆ {success_count}/{len(self.scenes)} ä¸ªè§†é¢‘")

        if failed_scenes:
            print(f"\nâš ï¸  å¤±è´¥åœºæ™¯ï¼š")
            for sid, error in failed_scenes:
                print(f"   - {sid}: {error[:50]}")

        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    generator = SceneVideoGenerator(
        script_path='./æ–‡è„‰è–ªä¼ _ç»†åŒ–è„šæœ¬.yaml',
        image_dir='./storyboards/æ–‡è„‰è–ªä¼ /doubao_images',
        keyframe_dir='./storyboards/æ–‡è„‰è–ªä¼ /keyframes',
        output_dir='./storyboards/æ–‡è„‰è–ªä¼ /scene_videos'
    )

    await generator.generate_all_videos()


if __name__ == "__main__":
    asyncio.run(main())
