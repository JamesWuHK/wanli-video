#!/usr/bin/env python3
"""
é‡æ–°ç”Ÿæˆæœ€ç»ˆè§†é¢‘ï¼Œä¿®å¤å­—å¹•æ˜¾ç¤ºé—®é¢˜å¹¶æ·»åŠ èƒŒæ™¯éŸ³ä¹
"""

import os
import yaml
import subprocess
import asyncio
from pathlib import Path
import edge_tts


class FinalVideoGenerator:
    """æœ€ç»ˆè§†é¢‘ç”Ÿæˆå™¨ - ä¿®å¤å­—å¹• + æ·»åŠ BGM"""

    def __init__(self, script_path: str, image_dir: str, keyframe_dir: str, output_dir: str):
        """åˆå§‹åŒ–"""
        self.script_path = script_path
        self.image_dir = Path(image_dir)
        self.keyframe_dir = Path(keyframe_dir)
        self.output_dir = Path(output_dir)
        self.audio_dir = self.output_dir / "audio"
        self.temp_dir = self.output_dir / "temp"

        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.audio_dir.mkdir(parents=True, exist_ok=True)
        self.temp_dir.mkdir(parents=True, exist_ok=True)

        # åŠ è½½è„šæœ¬
        with open(script_path, 'r', encoding='utf-8') as f:
            self.script_data = yaml.safe_load(f)

        self.scenes = self.script_data.get('scenes', [])
        self.voice = self.script_data.get('project', {}).get('voice', 'zh-CN-YunxiNeural')

    async def generate_narration_audio(self, scene_id: str, narration: str) -> Path:
        """ç”Ÿæˆç”»å¤–éŸ³éŸ³é¢‘"""
        audio_path = self.audio_dir / f"{scene_id}.mp3"

        if audio_path.exists():
            return audio_path

        communicate = edge_tts.Communicate(narration, self.voice)
        await communicate.save(str(audio_path))
        return audio_path

    def get_audio_duration(self, audio_path: Path) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        cmd = [
            'ffprobe', '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        return float(result.stdout.strip())

    def create_subtitle_file(self, scene_id: str, narration: str, duration: float) -> Path:
        """åˆ›å»ºSRTå­—å¹•æ–‡ä»¶"""
        subtitle_path = self.temp_dir / f"{scene_id}.srt"

        # åˆ›å»ºSRTæ ¼å¼å­—å¹•
        with open(subtitle_path, 'w', encoding='utf-8') as f:
            f.write("1\n")
            f.write(f"00:00:00,000 --> 00:00:{int(duration):02d},{int((duration % 1) * 1000):03d}\n")
            f.write(f"{narration}\n")

        return subtitle_path

    def create_scene_video_with_subtitle(
        self,
        start_frame: Path,
        keyframe: Path,
        audio_path: Path,
        subtitle_path: Path,
        duration: float,
        output_path: Path
    ):
        """åˆ›å»ºå¸¦å­—å¹•çš„åœºæ™¯è§†é¢‘"""

        # å­—å¹•æ ·å¼ï¼šä½¿ç”¨subtitlesæ»¤é•œ
        # ä¼˜åŒ–å­—å¹•æ˜¾ç¤º - æ— é˜´å½±ã€æ›´é€æ˜ã€æ›´å°ã€æ›´é ä¸‹
        # PrimaryColour: &HB3FFFFFF (30%é€æ˜çš„ç™½è‰²)
        # BackColour: &H00000000 (å®Œå…¨é€æ˜èƒŒæ™¯)
        # MarginV: 30 (è·ç¦»åº•éƒ¨æ›´è¿‘ï¼Œå€¼è¶Šå°è¶Šé ä¸‹)
        # FontSize: 20 (æ›´å°å­—ä½“)
        # Shadow: 0 (æ— é˜´å½±)
        filter_complex = (
            # è¾“å…¥1: å¼€å§‹å¸§ï¼Œæ˜¾ç¤ºä¸€åŠæ—¶é•¿
            f"[0:v]scale=2048:1152,fps=30,trim=duration={duration/2}[v0];"
            # è¾“å…¥2: å…³é”®å¸§ï¼Œæ˜¾ç¤ºä¸€åŠæ—¶é•¿
            f"[1:v]scale=2048:1152,fps=30,trim=duration={duration/2}[v1];"
            # æ·¡å…¥æ·¡å‡ºè¿‡æ¸¡
            f"[v0][v1]xfade=transition=fade:duration=1:offset={duration/2-1}[v];"
            # æ·»åŠ å­—å¹• - ä¼˜åŒ–æ ·å¼ï¼ˆæ— é˜´å½±ã€æ›´é€æ˜ï¼‰
            f"[v]subtitles='{subtitle_path}':force_style='FontName=PingFang SC,FontSize=20,PrimaryColour=&HB3FFFFFF,OutlineColour=&H000000,BackColour=&H00000000,Bold=0,Outline=1,Shadow=0,MarginV=30,Alignment=2'[vout]"
        )

        cmd = [
            'ffmpeg', '-y',
            '-loop', '1', '-t', str(duration), '-i', str(start_frame),
            '-loop', '1', '-t', str(duration), '-i', str(keyframe),
            '-i', str(audio_path),
            '-filter_complex', filter_complex,
            '-map', '[vout]',
            '-map', '2:a',
            '-c:v', 'libx264',
            '-preset', 'medium',
            '-crf', '23',
            '-pix_fmt', 'yuv420p',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-shortest',
            str(output_path)
        ]

        subprocess.run(cmd, check=True, capture_output=True)

    async def create_scene_video(self, scene_index: int):
        """åˆ›å»ºå•ä¸ªåœºæ™¯è§†é¢‘"""
        scene = self.scenes[scene_index]
        scene_id = scene['id']
        duration = scene['duration']
        narration = scene['narration']

        print(f"\nğŸ¬ åœºæ™¯ {scene_index + 1}/{len(self.scenes)}: {scene_id}")

        # 1. ç”Ÿæˆæˆ–è·å–ç”»å¤–éŸ³
        audio_path = await self.generate_narration_audio(scene_id, narration)
        audio_duration = self.get_audio_duration(audio_path)

        # ä½¿ç”¨éŸ³é¢‘æ—¶é•¿ä½œä¸ºå®é™…è§†é¢‘æ—¶é•¿
        actual_duration = max(duration, audio_duration + 0.5)

        print(f"   ğŸ™ï¸  éŸ³é¢‘: {audio_duration:.2f}ç§’")
        print(f"   ğŸ“¹ è§†é¢‘: {actual_duration:.2f}ç§’")

        # 2. åˆ›å»ºå­—å¹•æ–‡ä»¶
        subtitle_path = self.create_subtitle_file(scene_id, narration, actual_duration)

        # 3. è·å–å›¾ç‰‡
        start_frame = self.image_dir / f"{scene_id}.png"
        keyframe = self.keyframe_dir / f"{scene_id}_keyframe.png"

        if not start_frame.exists() or not keyframe.exists():
            raise FileNotFoundError(f"å›¾ç‰‡ä¸å­˜åœ¨: {scene_id}")

        # 4. ç”Ÿæˆè§†é¢‘
        output_video = self.output_dir / f"{scene_id}.mp4"

        print(f"   ğŸ¨ ç”Ÿæˆè§†é¢‘ï¼ˆå¸¦å­—å¹•ï¼‰...")
        self.create_scene_video_with_subtitle(
            start_frame,
            keyframe,
            audio_path,
            subtitle_path,
            actual_duration,
            output_video
        )

        print(f"   âœ… å®Œæˆ: {output_video.name}")
        return output_video

    async def generate_all_scene_videos(self):
        """ç”Ÿæˆæ‰€æœ‰åœºæ™¯è§†é¢‘"""
        print("=" * 60)
        print("ğŸ¬ é‡æ–°ç”Ÿæˆæ‰€æœ‰åœºæ™¯è§†é¢‘ï¼ˆä¿®å¤å­—å¹•ï¼‰")
        print("=" * 60)

        scene_videos = []
        for i in range(len(self.scenes)):
            try:
                video_path = await self.create_scene_video(i)
                scene_videos.append(video_path)
            except Exception as e:
                print(f"   âŒ å¤±è´¥: {str(e)}")

        return scene_videos

    def merge_with_bgm(self, scene_videos: list, bgm_path: str, output_path: str):
        """åˆå¹¶è§†é¢‘å¹¶æ·»åŠ èƒŒæ™¯éŸ³ä¹"""
        print("\n" + "=" * 60)
        print("ğŸµ åˆå¹¶è§†é¢‘å¹¶æ·»åŠ èƒŒæ™¯éŸ³ä¹")
        print("=" * 60)

        # 1. åˆ›å»ºconcatæ–‡ä»¶
        concat_file = self.temp_dir / "concat_list.txt"
        with open(concat_file, 'w') as f:
            for video in scene_videos:
                f.write(f"file '{video.absolute()}'\n")

        # 2. å…ˆåˆå¹¶æ‰€æœ‰è§†é¢‘
        merged_video = self.temp_dir / "merged_no_bgm.mp4"

        print("\nğŸ“¹ åˆå¹¶æ‰€æœ‰åœºæ™¯è§†é¢‘...")
        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat',
            '-safe', '0',
            '-i', str(concat_file),
            '-c', 'copy',
            str(merged_video)
        ]
        subprocess.run(cmd, check=True, capture_output=True)

        # 3. è·å–è§†é¢‘æ—¶é•¿
        duration = self.get_audio_duration(merged_video)
        print(f"   æ€»æ—¶é•¿: {duration:.2f}ç§’")

        # 4. æ·»åŠ èƒŒæ™¯éŸ³ä¹
        if bgm_path and Path(bgm_path).exists():
            print(f"\nğŸµ æ·»åŠ èƒŒæ™¯éŸ³ä¹: {bgm_path}")

            # æ··åˆåŸéŸ³å’ŒèƒŒæ™¯éŸ³ä¹ï¼ˆèƒŒæ™¯éŸ³ä¹éŸ³é‡é™ä½ï¼‰
            cmd = [
                'ffmpeg', '-y',
                '-i', str(merged_video),
                '-stream_loop', '-1',  # å¾ªç¯æ’­æ”¾BGM
                '-i', bgm_path,
                '-filter_complex',
                '[0:a]volume=1.0[a0];[1:a]volume=0.15[a1];[a0][a1]amix=inputs=2:duration=first[aout]',
                '-map', '0:v',
                '-map', '[aout]',
                '-c:v', 'copy',
                '-c:a', 'aac',
                '-b:a', '192k',
                '-shortest',
                str(output_path)
            ]
            subprocess.run(cmd, check=True, capture_output=True)
            print(f"   âœ… å®Œæˆï¼BGMå·²æ·»åŠ ")
        else:
            print("\nâš ï¸  æœªæä¾›BGMæ–‡ä»¶ï¼Œä»…åˆå¹¶è§†é¢‘")
            import shutil
            shutil.copy(merged_video, output_path)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        merged_video.unlink(missing_ok=True)
        concat_file.unlink()

        print(f"\nğŸ“ è¾“å‡º: {output_path}")
        print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""

    generator = FinalVideoGenerator(
        script_path='./æ–‡è„‰è–ªä¼ _ç»†åŒ–è„šæœ¬.yaml',
        image_dir='./storyboards/æ–‡è„‰è–ªä¼ /doubao_images',
        keyframe_dir='./storyboards/æ–‡è„‰è–ªä¼ /keyframes',
        output_dir='./storyboards/æ–‡è„‰è–ªä¼ /final_videos'
    )

    # 1. ç”Ÿæˆæ‰€æœ‰åœºæ™¯è§†é¢‘
    scene_videos = await generator.generate_all_scene_videos()

    # 2. åˆå¹¶å¹¶æ·»åŠ BGM
    # æ³¨æ„ï¼šéœ€è¦å‡†å¤‡ä¸€ä¸ªBGMæ–‡ä»¶ï¼Œæˆ–è€…è®¾ç½®ä¸ºNone
    bgm_path = None  # å¦‚æœæœ‰BGMæ–‡ä»¶ï¼Œè®¾ç½®è·¯å¾„ï¼Œä¾‹å¦‚ï¼š'./bgm/traditional_chinese.mp3'

    output_path = './storyboards/æ–‡è„‰è–ªä¼ /æ–‡è„‰è–ªä¼ _å®Œæ•´ç‰ˆ_å¸¦BGM.mp4'

    generator.merge_with_bgm(scene_videos, bgm_path, output_path)

    print("\nâœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"ğŸ“¹ æœ€ç»ˆè§†é¢‘: {output_path}")


if __name__ == "__main__":
    asyncio.run(main())
